{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "s5S5TIObLKRs"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import urllib.request\n",
        "from urllib.request import quote\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# 라이브 커머스 , 라방 키워드로 네이버 기사 크롤링 \n",
        "\n",
        "def get_news(query, page_num = 10):\n",
        "\n",
        "  news_df = pd.DataFrame(columns = (\"Title\", \"press\", \"Datetime\", \"Article\", \"Link\"))\n",
        "  index = 0\n",
        "\n",
        "  url_query =  quote(query)  # utf_8 로 인코딩 \n",
        "\n",
        "  # 네이버 넘어가기 한계로 두번에 나누어서 진행 \n",
        "  # 라방 라이브커머스 라이브쇼핑 \n",
        "  # 첫번째 \n",
        "  #url = \"https://search.naver.com/search.naver?where=news&sm=tab_opt&sort=2&photo=0&field=0&pd=3&ds=2021.01.01&de=2022.12.09&docid=&related=0&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so%3Ar%2Cp%3Afrom20210101to20221209&is_sug_officeid=0&query=\" + url_query\n",
        "  # 두번째 \n",
        "  url = \"https://search.naver.com/search.naver?where=news&sm=tab_opt&sort=2&photo=0&field=0&pd=3&ds=2022.04.29&de=2022.12.09&docid=&related=0&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so%3Ar%2Cp%3Afrom20220429to20221209&is_sug_officeid=0&query=\" + url_query\n",
        "\n",
        "  \n",
        "  for _ in range(0, page_num):\n",
        "    serch_url = urllib.request.urlopen(url).read()\n",
        "    soup = BeautifulSoup(serch_url, 'html.parser')\n",
        "    links = soup.find_all('div', {'class' : 'info_group'})\n",
        "    \n",
        "    for link in links:\n",
        "          press = link.find('a', {'class' :\"info press\"}).get_text()\n",
        "          news_url = link.find('a' ,{'class' :'info'}).get('href') # 뉴스 기사 가지고 오기  \n",
        "\n",
        "          # 네이버 기사아 아닐경우를 대비해서 두번째 url이 없으면 그만둔다. \n",
        "          try:\n",
        "              news_url = link.select('a.info')[1].get('href')\n",
        "              news_link = urllib.request.urlopen(news_url).read()\n",
        "              news_html = BeautifulSoup(news_link,'html.parser')\n",
        "\n",
        "              title = news_html.find('h2' ,{'id':\"title_area\"}).get_text()\n",
        "              datetime = news_html.find('span' , {'class':\"media_end_head_info_datestamp_time _ARTICLE_DATE_TIME\"}).get_text()\n",
        "              # article = news_html.find('div' ,{'id': \"dic_area\"}).get_text()\n",
        "              # article = article.replace('\\n','')\n",
        "              # article = article.replace('\\t','')\n",
        "\n",
        "              news_df.loc[index] = [title, press, datetime,news_url]\n",
        "              index += 1\n",
        "\n",
        "              # print(\"#\", end=\"\") \n",
        "\n",
        "          except:\n",
        "              continue\n",
        "\n",
        "    try:\n",
        "      next = soup.find('a',{'class' :'btn_next'}).get('href')\n",
        "      url = \"https://search.naver.com/search.naver\" + next\n",
        "    except:\n",
        "      break  \n",
        "                \n",
        "  return news_df #이게 왜 안먹히지?\n",
        "        \n",
        "\n",
        "        \n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HGF1WFlt0EK",
        "outputId": "33096a58-c57e-462a-b23a-df5b2ded6a79"
      },
      "outputs": [],
      "source": [
        "# url 1번째\n",
        "query = input('검색 질의 :')\n",
        "news_live_1 = get_news(query, 2000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6ttZcJmLqwK",
        "outputId": "33096a58-c57e-462a-b23a-df5b2ded6a79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "검색 질의 :라방 라이브커머스 라이브쇼핑\n"
          ]
        }
      ],
      "source": [
        "# url 2번째\n",
        "query = input('검색 질의 :')\n",
        "news_live_2 = get_news(query, 2000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVpPKHibleG9"
      },
      "outputs": [],
      "source": [
        "news_live_2['Datetime'] = news_live_2['Datetime'].str.split(' ',1).str[0]\n",
        "news_live_2['Datetime']  = pd.to_datetime(news_live_2['Datetime'])\n",
        "news_live_2.to_csv('article_2000_2.csv', index = False ,encoding=\"utf-8-sig\" )\n",
        "news_live_2"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "7210e968467d1ef0b92da6e267d367c665d81f972781a6ccd792eac802b7fd99"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
